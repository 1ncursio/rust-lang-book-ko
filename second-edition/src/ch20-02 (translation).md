## 서버를 싱글 스레드에서 멀티 스레드로 바꾸기

현재, 서버는 한번에 하나의 요청만 처리할 것입니다.
즉 첫번째 요청에 대한 작업이 끝나기 전에 두번째 요청이 들어온다면
앞선 작업이 끝날때까지 대기하게 됩니다. 만약 서버가 훨씬 더 많은
요청을 받게 된다면, 처리는 점점 더 늦어지게 됩니다.
나중에 들어온 요청은 앞선 요청보다 더 빠르게 처리 될 수 있더라도
긴 시간을 기다려야 할 것입니다.
우린 이 문제를 해결해야 합니다만, 먼저 현재 우리의 문제를 살펴보도록 하죠.

### 현재 서버에서 느린 요청을 시뮬레이팅하기

우린 현재의 우리가 만든 서버에서 느린 요청이 어떻게
다른 요청들에게 영향을 미칠 수 있는지 살펴 볼 것입니다.
예제 20-10은 `/sleep` 요청을 처리할때 응답하기 전에
5초간 서버를 멈추도록 하여 느린 요청을 시뮬레이션 합니다.

<span class="filename">파일명: src/main.rs</span>

```rust
use std::thread;
use std::time::Duration;
# use std::io::prelude::*;
# use std::net::TcpStream;
# use std::fs::File;
// --생략--

fn handle_connection(mut stream: TcpStream) {
#     let mut buffer = [0; 512];
#     stream.read(&mut buffer).unwrap();
    // --생략--

    let get = b"GET / HTTP/1.1\r\n";
    let sleep = b"GET /sleep HTTP/1.1\r\n";

    let (status_line, filename) = if buffer.starts_with(get) {
        ("HTTP/1.1 200 OK\r\n\r\n", "hello.html")
    } else if buffer.starts_with(sleep) {
        thread::sleep(Duration::from_secs(5));
        ("HTTP/1.1 200 OK\r\n\r\n", "hello.html")
    } else {
        ("HTTP/1.1 404 NOT FOUND\r\n\r\n", "404.html")
    };

    // --생략--
}
```

<span class="caption">예제 20-10: `/sleep` 요청을 인식할시 5초간
멈춤으로써 느린 요청을 시뮬레이션 하기</span>

이 코드는 좀 지저분하지만 시뮬레이션 용도로는 충분합니다.
우리는 우리 서버가 인식할 두번째 요청인 `sleep` 을 생성하고.
`/sleep` 으로의 요청을 처리할 `else if` 를
`if` 블록 뒤에 추가했습니다. 만약 요청이 들어오면,
서버는 HTML 페이지를 렌더링 하기 전에 5초간 대기할 것입니다.

여러분은 우리 서버가 얼마나 부족한지 알 수 있습니다:
실제 라이브러리들은 훨씬 간단한 방법으로 여러개의 요청을 구분할 것입니다

`cargo run` 를 이용해 서버를 실행시키고, 두 브라우저 창을 엽니다:
하나는 `http://localhost:7878/` 로 접속하고 다른 하나는 `http://localhost:7878/sleep` 으로 접속합니다.
만약 여러분이 `/` URI로 몇번 접속하시면 기존 처럼
빠른 응답을 보실 수 있으실 테지만, `/sleep` 으로 접속하고 `/` 로 접속한다면
`sleep` 이 5초동안의 로딩을 끝내고 나서야 `/` 에 대한 응답을 보실 수 있을겁니다.

우리 웹 서버가 모든 요청들을 느린 요청 뒤에 처리하도록 하는것을
피하는 방법은 여러가지가 있지만, 그중 우리가 사용할 방법은
스레드 풀 (thread pool) 입니다.

### 스레드 풀을 이용한 처리량 증진

*스레드 풀* 은 대기중이거나 작업을 처리할 준비가 되어 있는
스레드들의 그룹입니다. 프로그램이 새 작업을 받았을때,
스레드 풀은 작업을 pool 안에 있는 스레드중 하나에게 맡기고
해당 스레드가 작업을 처리하도록 합니다. 남은 스레드들은
첫번째 스레드가 처리중인 동안 들어온 작업을 언제든지 처리할 수
있도록 합니다. 첫번째 스레드가 작업을 끝마치면 pool로 돌아와
작업 대기상태가 됩니다. 스레드 풀은 우리가 여러 커넥션들을
동시에 처리할 수 있게 해주고 우리 서버의 처리량을 증가시킵니다.

우린 Dos (Denial of Service) 공격을 막기 위해 pool 안의
스레드 개수에 대한 제한을 작게 둘 것입니다;
만약 우리 프로그램이 각각의 요청이 들어올때마다 새 스레드를 생성한다면
누군가 우리 서버에 10만개의 요청을 보냈을때 우리 서버는
서버의 모든 리소스를 사용하고 모든 요청이 끝날때까지 처리가 계속될 것입니다.

우린 스레드를 제한없이 생성하는것이 아닌 pool 안에서 대기할
고정된 개수의 스레드를 가질 것입니다. 요청이 들어온다면,
요청들은 처리를 위해 pool로 보내지고, pool에선 들어오는 요청들에
대한 queue 를 유지할 것입니다. pool 내의 각 스레드들은 이 queue에서
요청을 꺼내서 처리하고 또 다른 요청이 있는지 queue에 물어봅니다.
우린 이 형태를 이용해 동시에 `N` 개의 요청을 처리할 수 있습니다. 여기서 `N` 은 스레드의 개수입니다.
만약 각각의 스레드가 응답하는데 오래 걸리는 요청을 처리하게되면
그 다음의 요청들은 여전히 queue에 남아있게 됩니다만,
이전보다 처리할 수 있는 요청은 늘어났습니다

이 기술은 우리 웹서버의 처리량을 증가시킬 수많은 방법중 하나일 뿐입니다.
여러분이 찾으실 다른 방법들은 fork/jon 모델과 싱글 스레드 기반
비동기 I/O 모델 등일 것입니다. 만약 여러분이 이러한 내용에 관심이
있으시다면, 다른 해결책들에 대해 좀 더 자세히 찾아보시고 Rust로 구현해 보세요;
Rust같은 저레벨 언어로는 이와 같은 방법들이 전부 가능합니다.

스레드 풀을 구현하기 전에, pool 이 어떻게 쓰여야 할지 이야기 해 봅시다.
여러분이 코드를 디자인할때, 클라이언트 인터페이스를 먼저 작성해 보는건
여러분의 디자인에 도움이 될 수 있습니다.
코드의 API 를 작성하여 원하는 방식으로 구성한 다음
기능을 구현하고 공개 API를 디자인하는 대신
해당 구조 내에서 기능을 구현하세요.

12장의 프로젝트에서 테스트 주도 개발을 할때와 흡사하게,
우린 여기서 컴파일러 주도 개발을 할 것입니다. 우리가 원하는대로
기능을 호출하는 코드를 작성하고, 컴파일러로부터의 에러를 조사하여
우리가 다음엔 어떻게 코드를 변화시켜야 작동시킬 수 있을지 알아냅니다.

